{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Company Q&A Matching Notebook\n",
    "\n",
    "This notebook loads the preprocessed **two-column data** (ID, `text`) for **company profiles** and **job postings**, splits each text **into paragraph-level chunks**, performs **bi-encoder retrieval** with `jinaai/jina-embeddings-v3` for a set of questions, and **re-ranks** the top matches with a **cross-encoder**.\n",
    "\n",
    "**Output:** a **DataFrame with one row per company** (company ID + answers per question) that is saved to disk."
   ],
   "id": "bb95b4ed1b5b77af"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "e1e7a65ca78a60d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Paths to the prepared datasets (two columns: ID + 'text')\n",
    "COMPANIES_PARQUET = Path(\"companies_two_columns.parquet\")\n",
    "COMPANIES_CSV     = Path(\"companies_two_columns.csv\")\n",
    "\n",
    "JOBS_PARQUET      = Path(\"jobs_two_columns.parquet\")\n",
    "JOBS_CSV          = Path(\"jobs_two_columns.csv\")\n",
    "\n",
    "# Column names\n",
    "COMPANY_ID_COL    = \"prsId\"    # adjust if different\n",
    "COMPANY_TEXT_COL  = \"text\"     # expected to be 'text'\n",
    "\n",
    "JOB_ID_COL        = \"jobId\"    # informative; not required in final output\n",
    "JOB_TEXT_COL      = \"text\"\n",
    "JOB_COMPANY_ID_COL= \"prsId\"    # foreign key Job -> Company (adjust if needed)\n",
    "\n",
    "# Questions: either via OCR from an image OR manually defined\n",
    "QUESTIONS_IMAGE_PATH = None  # e.g., Path(\"questions.png\") or None\n",
    "QUESTIONS_MANUAL = [\n",
    "    # Put your questions here (order matters) if no image is used.\n",
    "    \"Which technologies does the company use?\",\n",
    "    \"Does the company offer remote work?\",\n",
    "    \"What benefits are mentioned in job postings?\",\n",
    "]\n",
    "\n",
    "# Retrieval / Ranking params\n",
    "BI_ENCODER_MODEL      = \"jinaai/jina-embeddings-v3\"\n",
    "CROSS_ENCODER_MODEL   = \"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n",
    "TOP_K_BI_PER_COMPANY  = 10    # how many candidates per question/company to pass to the cross-encoder\n",
    "MAX_PARAGRAPH_LEN     = 20000 # hard cap for a single paragraph (characters)\n",
    "MIN_PARAGRAPH_CHARS   = 20    # filter out very short paragraphs\n",
    "BATCH_SIZE_EMB        = 64\n",
    "BATCH_SIZE_CROSS      = 64\n",
    "\n",
    "# Output\n",
    "OUTPUT_CSV     = Path(\"company_answers.csv\")\n",
    "OUTPUT_PARQUET = Path(\"company_answers.parquet\")"
   ],
   "id": "5b8e60166d66a283"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Load Data",
   "id": "4a335a29594f99eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def _load_two_col(path_parquet: Path, path_csv: Path, id_col: str, text_col: str) -> pd.DataFrame:\n",
    "    if path_parquet.exists():\n",
    "        df = pd.read_parquet(path_parquet)\n",
    "    elif path_csv.exists():\n",
    "        df = pd.read_csv(path_csv)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Neither {path_parquet} nor {path_csv} was found.\")\n",
    "    # Standardize\n",
    "    if id_col not in df.columns or text_col not in df.columns:\n",
    "        raise KeyError(f\"Expected columns not found: id_col={id_col}, text_col={text_col}. Got: {df.columns.tolist()}\")\n",
    "    df = df[[id_col, text_col]].dropna().drop_duplicates()\n",
    "    return df\n",
    "\n",
    "companies = _load_two_col(COMPANIES_PARQUET, COMPANIES_CSV, COMPANY_ID_COL, COMPANY_TEXT_COL)\n",
    "jobs      = _load_two_col(JOBS_PARQUET, JOBS_CSV, JOB_ID_COL, JOB_TEXT_COL)\n",
    "\n",
    "# Ensure we have a join key from jobs -> company\n",
    "if JOB_COMPANY_ID_COL not in jobs.columns:\n",
    "    for cand in [\"prsId\", \"companyId\", \"company_id\", \"employerId\"]:\n",
    "        if cand in jobs.columns:\n",
    "            JOB_COMPANY_ID_COL = cand\n",
    "            break\n",
    "    else:\n",
    "        raise KeyError(f\"Join column for Jobs->Company not found. Please set JOB_COMPANY_ID_COL. Available: {jobs.columns.tolist()}\")\n",
    "\n",
    "display(companies.head())\n",
    "display(jobs.head())"
   ],
   "id": "8d3a70a78010f01c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chunking",
   "id": "715f1a81f8c1e22c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "PARA_SPLIT_RE = re.compile(r\"\\n\\s*\\n+\")\n",
    "\n",
    "def split_into_paragraphs(text: str) -> List[str]:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    paras = [p.strip() for p in PARA_SPLIT_RE.split(text) if p.strip()]\n",
    "    # Fallback if no double newlines: split by single newlines\n",
    "    if len(paras) <= 1 and \"\\n\" in text:\n",
    "        paras = [p.strip() for p in text.split(\"\\n\") if p.strip()]\n",
    "    # Filter & truncate\n",
    "    clean = []\n",
    "    for p in paras:\n",
    "        if len(p) >= MIN_PARAGRAPH_CHARS:\n",
    "            if len(p) > MAX_PARAGRAPH_LEN:\n",
    "                p = p[:MAX_PARAGRAPH_LEN]\n",
    "            clean.append(p)\n",
    "    return clean"
   ],
   "id": "e8ae5bcc1a7a5c3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Company Corpus (profiles + job postings)",
   "id": "550e67d3b1572046"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Map: company_id -> list of (chunk_text, source_type, source_id)\n",
    "company_corpus = defaultdict(list)\n",
    "\n",
    "# Company profiles\n",
    "for _, row in companies.iterrows():\n",
    "    cid = row[COMPANY_ID_COL]\n",
    "    for para in split_into_paragraphs(row[COMPANY_TEXT_COL]):\n",
    "        company_corpus[cid].append((para, \"company_profile\", cid))\n",
    "\n",
    "# Job postings\n",
    "if JOB_COMPANY_ID_COL not in jobs.columns:\n",
    "    raise KeyError(f\"Join column {JOB_COMPANY_ID_COL} missing in jobs.\")\n",
    "for _, row in jobs.iterrows():\n",
    "    cid = row[JOB_COMPANY_ID_COL]\n",
    "    for para in split_into_paragraphs(row[JOB_TEXT_COL]):\n",
    "        company_corpus[cid].append((para, \"job_posting\", row[JOB_ID_COL]))\n",
    "\n",
    "num_companies = len(company_corpus)\n",
    "num_chunks = sum(len(v) for v in company_corpus.values())\n",
    "print(f\"Companies in corpus: {num_companies} | Total chunks: {num_chunks}\")"
   ],
   "id": "1a1c050b20382ce5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:16:54.711280Z",
     "start_time": "2025-09-09T09:16:54.692005Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Load Quastions",
   "id": "cf7d06f9b1a00648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List\n",
    "import re\n",
    "\n",
    "def read_questions_from_image(img_path: Path) -> List[str]:\n",
    "    import pytesseract\n",
    "    from PIL import Image\n",
    "    text = pytesseract.image_to_string(Image.open(img_path))\n",
    "    # naive split by line breaks\n",
    "    qs = [q.strip(\"-â€¢:\\t\") for q in re.split(r\"\\n+|\\r+\", text) if q.strip()]\n",
    "    # heuristic: remove very short fragments\n",
    "    qs = [q for q in qs if len(q) > 5 and (q.endswith(\"?\") or q.lower().startswith(\n",
    "        (\"what\", \"which\", \"how\", \"does\", \"is\", \"are\", \"has\", \"have\", \"when\", \"where\", \"why\")))]\n",
    "    return qs\n",
    "\n",
    "if QUESTIONS_IMAGE_PATH:\n",
    "    QUESTIONS = read_questions_from_image(Path(QUESTIONS_IMAGE_PATH))\n",
    "else:\n",
    "    QUESTIONS = [q.strip() for q in QUESTIONS_MANUAL if q and isinstance(q, str)]\n",
    "\n",
    "print(\"Questions:\", QUESTIONS)"
   ],
   "id": "19074ae8f53fcbbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Matching",
   "id": "29404afc6c1e2c53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bi-Encoder Retrieval",
   "id": "cc1d0cfb9d184aaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bi_encoder = SentenceTransformer(BI_ENCODER_MODEL, device=device, trust_remote_code=True)\n",
    "\n",
    "# Prepare global list of all chunks + mapping\n",
    "all_chunks = []\n",
    "chunk_company_idx = []  # (company_id, idx_in_company)\n",
    "for cid, chunks in company_corpus.items():\n",
    "    for i, (txt, src, sid) in enumerate(chunks):\n",
    "        all_chunks.append(txt)\n",
    "        chunk_company_idx.append((cid, i))\n",
    "\n",
    "# Encode all chunks\n",
    "chunk_emb = bi_encoder.encode(\n",
    "    all_chunks,\n",
    "    batch_size=BATCH_SIZE_EMB,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Encode questions\n",
    "question_emb = bi_encoder.encode(\n",
    "    QUESTIONS,\n",
    "    batch_size=BATCH_SIZE_EMB,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "# Map: company -> indices in global embedding array\n",
    "company_to_global_indices = {}\n",
    "offset = 0\n",
    "for cid, chunks in company_corpus.items():\n",
    "    n = len(chunks)\n",
    "    company_to_global_indices[cid] = list(range(offset, offset+n))\n",
    "    offset += n\n",
    "\n",
    "print(f\"Embeddings ready: chunks={chunk_emb.shape}, questions={question_emb.shape}, device={device}\")"
   ],
   "id": "a5f6635d06d69e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cross Encoder Reranking",
   "id": "6d44bce3db930d34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder(CROSS_ENCODER_MODEL, device=device)\n",
    "\n",
    "def answer_for_company(cid, q_idx, top_k=TOP_K_BI_PER_COMPANY):\n",
    "    # Candidates via Bi-Encoder cosine similarity within the company\n",
    "    gidx = company_to_global_indices.get(cid, [])\n",
    "    if not gidx:\n",
    "        return None, None, None\n",
    "\n",
    "    q_vec = question_emb[q_idx].unsqueeze(0)  # (1, d)\n",
    "    cand_emb = chunk_emb[gidx]                # (m, d)\n",
    "    scores = torch.matmul(cand_emb, q_vec.T).squeeze(1)  # (m,)\n",
    "    topv, topi = torch.topk(scores, k=min(top_k, len(gidx)))\n",
    "    top_global_indices = [gidx[int(i)] for i in topi]\n",
    "\n",
    "    # Cross-Encoder reranking\n",
    "    pairs = [(QUESTIONS[q_idx], all_chunks[idx]) for idx in top_global_indices]\n",
    "    rerank_scores = cross_encoder.predict(pairs, batch_size=BATCH_SIZE_CROSS, convert_to_tensor=True)\n",
    "    best_idx = int(torch.argmax(torch.tensor(rerank_scores)))\n",
    "    best_global_idx = top_global_indices[best_idx]\n",
    "    best_text = all_chunks[best_global_idx]\n",
    "    best_score = float(rerank_scores[best_idx])\n",
    "    return best_text, best_score, best_global_idx\n",
    "\n",
    "# Example test (optional)\n",
    "# sample_cid = next(iter(company_corpus.keys()))\n",
    "# print(answer_for_company(sample_cid, 0))"
   ],
   "id": "5fd86dfe8fdc7e14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Build Answers per Company & Save",
   "id": "d7605167f1283139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# If you specifically want only 5 candidates re-ranked, set:\n",
    "# TOP_K_BI_PER_COMPANY = 5  # (override the config above if needed)\n",
    "\n",
    "answer_cols = [f\"answer_q{i+1}\" for i in range(len(QUESTIONS))]\n",
    "# (Optional) keep provenance for debugging/auditing\n",
    "prov_cols = [f\"prov_q{i+1}\" for i in range(len(QUESTIONS))]\n",
    "\n",
    "rows = []\n",
    "for cid in tqdm(company_corpus.keys(), desc=\"Building answers\"):\n",
    "    answers = []\n",
    "    provs = []\n",
    "    for q_idx in range(len(QUESTIONS)):\n",
    "        best_text, best_score, best_global_idx = answer_for_company(cid, q_idx)\n",
    "        answers.append(best_text if best_text is not None else \"\")\n",
    "        provs.append(best_score if best_score is not None else None)\n",
    "    row = {COMPANY_ID_COL: cid}\n",
    "    row.update({col: ans for col, ans in zip(answer_cols, answers)})\n",
    "    # Add provenance as separate columns (optional â€” comment out if not needed)\n",
    "    row.update({col: pr for col, pr in zip(prov_cols, provs)})\n",
    "    rows.append(row)\n",
    "\n",
    "df_answers = pd.DataFrame(rows, columns=[COMPANY_ID_COL] + answer_cols + prov_cols)\n",
    "display(df_answers.head())\n",
    "\n",
    "# Save\n",
    "df_answers.to_csv(OUTPUT_CSV, index=False)\n",
    "try:\n",
    "    df_answers.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "except Exception as e:\n",
    "    print(\"Skipped Parquet save:\", e)\n",
    "\n",
    "print(f\"Saved to: {OUTPUT_CSV.resolve()}\")\n",
    "try:\n",
    "    print(f\"Saved to: {OUTPUT_PARQUET.resolve()}\")\n",
    "except:\n",
    "    pass"
   ],
   "id": "c61707296f69de69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

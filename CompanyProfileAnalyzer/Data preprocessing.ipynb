{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e940a87",
   "metadata": {},
   "source": [
    "# Minimal Data Preprocessing â€” ID + Cleaned Text Only\n",
    "\n",
    "This script converts company and job datasets into a **two-column format**:\n",
    "- an **ID** column (e.g., `prsId` for companies, `jobId` for jobs), and\n",
    "- a **cleaned text** column with all HTML removed.\n",
    "\n",
    "Designed to be drop-in: if you already have your DataFrames (`df_firmen`, `df_jobs`),\n",
    "skip the data loading step and directly use `to_two_columns`."
   ]
  },
  {
   "cell_type": "code",
   "id": "87165255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T14:52:40.496286Z",
     "start_time": "2025-09-04T14:52:38.115867Z"
    }
   },
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Union"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "fc580ecb",
   "metadata": {},
   "source": [
    "# Data Loading (Optional)\n",
    "Adjust file names / readers as needed.\n",
    "If your DataFrames `df_firmen` and `df_jobs` are already in memory,\n",
    "you can skip this entire section."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T14:59:48.091406Z",
     "start_time": "2025-09-04T14:59:48.042263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Try JSON Lines first; fall back to normal JSON if needed.\n",
    "def try_read_json_any(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a JSON Lines (.jsonl) file if possible; otherwise fall back to\n",
    "    standard JSON (.json). Raises FileNotFoundError if the path doesn't exist.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{path} not found. Please adjust the path.\")\n",
    "    try:\n",
    "        # JSON Lines (one JSON object per line)\n",
    "        return pd.read_json(path, lines=True, dtype=False)\n",
    "    except ValueError:\n",
    "        # Standard JSON (array or object)\n",
    "        return pd.read_json(path, dtype=False)\n",
    "\n",
    "# Example filenames (change as needed)\n",
    "firmen_path = Path(\"companies.jsonl\")  # or \"companies.json\"\n",
    "jobs_path   = Path(\"jobs.jsonl\")       # or \"jobs.json\"\n",
    "\n",
    "# Try to load; if it fails, we simply print a message so the script can continue\n",
    "try:\n",
    "    df_firmen = try_read_json_any(firmen_path)\n",
    "    df_jobs   = try_read_json_any(jobs_path)\n",
    "    print(\"Loaded dataframes: df_firmen and df_jobs\")\n",
    "except Exception as e:\n",
    "    print(\"Skipping data load (edit paths as needed). Error:\", e)"
   ],
   "id": "a8cc3c5dec0dc6a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping data load (edit paths as needed). Error: companies.jsonl not found. Please adjust the path.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Utilities\n",
    "Helper functions for text processing:\n",
    " - `strip_html`: removes HTML tags and collapses whitespace\n",
    " - `value_to_text`: converts lists, dicts, or scalars into a text string\n",
    " - `concat_row_text`: concatenates all non-ID column values in one row into text"
   ],
   "id": "761d62308d9ac32d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T15:00:59.993928Z",
     "start_time": "2025-09-04T15:00:59.966274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def strip_html(text: Union[str, float]) -> str:\n",
    "    \"\"\"Remove HTML tags and collapse whitespace. Robust to non-strings.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if pd.isna(text) else str(text)\n",
    "    # remove tags\n",
    "    no_tags = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    # unescape common entities (basic replacements)\n",
    "    no_entities = (no_tags\n",
    "        .replace(\"&nbsp;\", \" \")\n",
    "        .replace(\"&amp;\", \"&\")\n",
    "        .replace(\"&lt;\", \"<\")\n",
    "        .replace(\"&gt;\", \">\")\n",
    "        .replace(\"&quot;\", '\"')\n",
    "        .replace(\"&#39;\", \"'\"))\n",
    "    # collapse whitespace\n",
    "    return re.sub(r\"\\s+\", \" \", no_entities).strip()\n",
    "\n",
    "def value_to_text(val) -> str:\n",
    "    \"\"\"Convert scalars, lists, dicts to a compact text string.\"\"\"\n",
    "    if val is None:\n",
    "        return \"\"\n",
    "    if isinstance(val, (list, dict)):\n",
    "        try:\n",
    "            return json.dumps(val, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            return str(val)\n",
    "    return str(val)\n",
    "\n",
    "def concat_row_text(row: pd.Series, exclude_cols: Iterable[str]) -> str:\n",
    "    \"\"\"Concatenate all non-ID column values into a single string.\"\"\"\n",
    "    parts = []\n",
    "    for col, val in row.items():\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        txt = value_to_text(val)\n",
    "        if txt:\n",
    "            parts.append(txt)\n",
    "    return \" \".join(parts)"
   ],
   "id": "f8ee3cedd8828740",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transform to Two-Column Format\n",
    "\n",
    "Convert a DataFrame into a minimal two-column format:\n",
    " - one column for the ID\n",
    " - one column for the cleaned text (all other fields concatenated and HTML-stripped)."
   ],
   "id": "e58adfb7695f3eb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T15:01:54.515875Z",
     "start_time": "2025-09-04T15:01:54.475474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_two_columns(df: pd.DataFrame, id_col: str, text_col_name: str = \"text\") -> pd.DataFrame:\n",
    "    if id_col not in df.columns:\n",
    "        raise KeyError(f\"ID column '{id_col}' not found in DataFrame.\")\n",
    "    # Build raw text by concatenating all non-ID columns\n",
    "    exclude = {id_col}\n",
    "    raw_text = df.apply(lambda row: concat_row_text(row, exclude_cols=exclude), axis=1)\n",
    "    # Clean HTML\n",
    "    cleaned = raw_text.apply(strip_html)\n",
    "    out = pd.DataFrame({id_col: df[id_col], text_col_name: cleaned})\n",
    "    # Drop rows where text is empty after cleaning\n",
    "    out = out[out[text_col_name].str.len() > 0].reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# Example usage (uncomment when df_firmen / df_jobs are available)\n",
    "# companies_two = to_two_columns(df_firmen, id_col=\"prsId\")  # -> columns: prsId, text\n",
    "# jobs_two      = to_two_columns(df_jobs,   id_col=\"jobId\")  # -> columns: jobId, text\n",
    "\n",
    "# Quick preview if dataframes are available\n",
    "try:\n",
    "    display(companies_two.head(3))\n",
    "    display(jobs_two.head(3))\n",
    "except NameError:\n",
    "    print(\"Define df_firmen / df_jobs and run the transformation to preview the result.\")"
   ],
   "id": "63032222a056d793",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define df_firmen / df_jobs and run the transformation to preview the result.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Save Results (Optional)\n",
    "\n",
    "Save the transformed two-column DataFrames to CSV or Parquet files."
   ],
   "id": "e52f7673ac1b99bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "companies_two.to_parquet(\"companies_two_columns.parquet\", index=False)\n",
    "jobs_two.to_parquet(\"jobs_two_columns.parquet\", index=False)\n",
    "\n",
    "companies_two.to_csv(\"companies_two_columns.csv\", index=False)\n",
    "jobs_two.to_csv(\"jobs_two_columns.csv\", index=False)"
   ],
   "id": "9e234e8c0b9b564a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
